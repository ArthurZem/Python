# -*- coding: utf-8 -*-
"""Transferencia de Aprendizado - Arthur Zem

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y-YvMxA22SrbexKrCBb6W6awCsvkJaaJ
"""

#@title MIT License
#
# Copyright (c) 2017 François Chollet                                                                                                                    # IGNORE_COPYRIGHT: cleared by OSS licensing
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the "Software"),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

"""# Transfer learning and fine-tuning

<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://www.tensorflow.org/tutorials/images/transfer_learning"><img src="https://www.tensorflow.org/images/tf_logo_32px.png" />View on TensorFlow.org</a>
  </td>
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb?force_kitty_mode=1&force_corgi_mode=1"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Run in Google Colab</a>
  </td>
  <td>
    <a target="_blank" href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb"><img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />View source on GitHub</a>
  </td>
  <td>
    <a href="https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/transfer_learning.ipynb"><img src="https://www.tensorflow.org/images/download_logo_32px.png" />Download notebook</a>
  </td>
</table>

**Classificar imagens de cães e gatos usando o aprendizado de transferência de uma rede pré-treinada**.

Um modelo pré-treinado é uma rede salva que foi previamente treinada em um grande conjunto de dados, normalmente em uma tarefa de classificação de imagem em grande escala. Você usa o modelo pré-treinado como está ou usa o aprendizado de transferência para personalizar esse modelo para uma determinada tarefa.

A intuição por trás do aprendizado de transferência para classificação de imagens é que, se um modelo for treinado em um conjunto de dados grande e geral o suficiente, esse modelo servirá efetivamente como um modelo genérico do mundo visual. Você pode aproveitar esses mapas de recursos aprendidos sem precisar começar do zero treinando um modelo grande em um grande conjunto de dados.

Neste notebook, você tentará duas maneiras de personalizar um modelo pré-treinado:

1. Extração de recursos: use as representações aprendidas por uma rede anterior para extrair recursos significativos de novas amostras. Você simplesmente adiciona um novo classificador, que será treinado do zero, em cima do modelo pré-treinado para que você possa redirecionar os mapas de recursos aprendidos anteriormente para o conjunto de dados.

  Você não precisa (re)treinar todo o modelo. A rede convolucional base já contém recursos que são genericamente úteis para classificar imagens. No entanto, a parte final de classificação do modelo pré-treinado é específica para a tarefa de classificação original e, posteriormente, específica para o conjunto de classes em que o modelo foi treinado.

2. Ajuste fino: Descongele algumas das camadas superiores de uma base de modelo congelada e treine em conjunto as camadas do classificador recém-adicionadas e as últimas camadas do modelo base. Isso nos permite "ajustar" as representações de recursos de ordem superior no modelo base para torná-las mais relevantes para a tarefa específica.

Você seguirá o fluxo de trabalho geral de aprendizado de máquina.

1. Examinar e entender os dados
2. Crie um pipeline de entrada, neste caso usando Keras ImageDataGenerator
3. Componha o modelo
  * Carregue no modelo base pré-treinado (e pesos pré-treinados)
  * Empilhe as camadas de classificação no topo
4. Treine o modelo
5. Avaliar modelo
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf

"""## Pré-processamento de dados

### Download de dados

Neste tutorial, você usará um conjunto de dados contendo vários milhares de imagens de cães e gatos. Faça download e extraia um arquivo zip contendo as imagens e crie um tf.data.Dataset para treinamento e validação usando o utilitário tf.keras.utils.image_dataset_from_directory . Você pode aprender mais sobre como carregar imagens neste [tutorial](https://www.tensorflow.org/tutorials/load_data/images).
"""

BATCH_SIZE = 32
IMG_SIZE = (160, 160)

_URL = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'
path_to_zip = tf.keras.utils.get_file('flower_photos.zip', origin=_URL, extract=True)
PATH = os.path.join(os.path.dirname(path_to_zip), 'flower_photos')

PATH

train_dataset = tf.keras.utils.image_dataset_from_directory(PATH,
                                                            shuffle=True,
                                                            batch_size=BATCH_SIZE,
                                                            image_size=IMG_SIZE,
                                                            validation_split = 0.2,
                                                            subset = "training",
                                                            seed = 132)

validation_dataset = tf.keras.utils.image_dataset_from_directory(PATH,
                                                                 shuffle=True,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE,
                                                                 validation_split = 0.2,
                                                                 subset = "validation",
                                                                 seed = 132)

"""Mostre as primeiras nove imagens e rótulos do conjunto de treinamento:

"""

class_names = train_dataset.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(15):
    ax = plt.subplot(3, 5, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""Como o conjunto de dados original não contém um conjunto de teste, você criará um. Para fazer isso, determine quantos lotes de dados estão disponíveis no conjunto de validação usando tf.data.experimental.cardinality e mova 20% deles para um conjunto de teste."""

val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)

print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))
print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))

"""### Configurar o conjunto de dados para desempenho

Use a pré-busca em buffer para carregar imagens do disco sem que a E/S se torne um bloqueio. Para saber mais sobre esse método, consulte o guia [data performance](https://www.tensorflow.org/guide/data_performance).
"""

AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)

"""### Use data augmentation

Quando você não tem um grande conjunto de dados de imagem, é uma boa prática introduzir artificialmente a diversidade de amostra aplicando transformações aleatórias, porém realistas, às imagens de treinamento, como rotação e inversão horizontal. Isso ajuda a expor o modelo a diferentes aspectos dos dados de treinamento e reduzir o overfitting .  [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit). Você pode aprender mais sobre o aumento de dados neste tutorial . [tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation).
"""

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('horizontal'),
  tf.keras.layers.RandomRotation(0.2),
])

"""Nota: Essas camadas ficam ativas apenas durante o treinamento, quando você chama Model.fit . Eles ficam inativos quando o modelo é usado no modo de inferência em Model.evaluate ou Model.fit .

Vamos aplicar repetidamente essas camadas na mesma imagem e ver o resultado.
"""

for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')

"""### Redimensionar valores de pixel

Em instantes, você fará o download do tf.keras.applications.MobileNetV2 para uso como modelo base. Este modelo espera valores de pixel em [-1, 1] , mas neste ponto, os valores de pixel em suas imagens estão em [0, 255] . Para redimensioná-los, use o método de pré-processamento incluído no modelo.
"""

preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

"""Observação: como alternativa, você pode redimensionar os valores de pixel de `[0, 255]` to `[-1, 1]` usando `tf.keras.layers.Rescaling`."""

rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)

"""Observação: se estiver usando outros tf.keras.applications , verifique o documento da API para determinar se eles esperam pixels em [-1, 1] ou [0, 1] ou use a função preprocess_input incluída.

## Crie o modelo base a partir dos convnets pré-treinados
Você criará o modelo base a partir do modelo MobileNet V2 desenvolvido no Google. Isso é pré-treinado no conjunto de dados ImageNet, um grande conjunto de dados que consiste em 1,4 milhão de imagens e 1.000 classes. ImageNet é um conjunto de dados de treinamento de pesquisa com uma ampla variedade de categorias, como jackfruit e syringe . Essa base de conhecimento nos ajudará a classificar cães e gatos de nosso conjunto de dados específico.

Primeiro, você precisa escolher qual camada do MobileNet V2 você usará para extração de recursos. A última camada de classificação (no "topo", pois a maioria dos diagramas de modelos de aprendizado de máquina vai de baixo para cima) não é muito útil. Em vez disso, você seguirá a prática comum de depender da última camada antes da operação de nivelamento. Essa camada é chamada de "camada de gargalo". Os recursos da camada de gargalo retêm mais generalidade em comparação com a camada final/superior.

Primeiro, instancie um modelo MobileNet V2 pré-carregado com pesos treinados no ImageNet. Ao especificar o argumento include_top=False , você carrega uma rede que não inclui as camadas de classificação na parte superior, o que é ideal para extração de recursos.
"""

IMG_SIZE

IMG_SHAPE = IMG_SIZE + (3,)

IMG_SHAPE

# Create the base model from the pre-trained model MobileNet V2

base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

base_model.summary()

"""Este extrator de recursos converte cada imagem de 160x160x3 em um bloco de recursos de 5x5x1280 . Vamos ver o que ele faz com um exemplo de lote de imagens:"""

image_batch, label_batch = next(iter(train_dataset))
feature_batch = base_model(image_batch)
print(feature_batch.shape)

"""## Extração de recursos
Nesta etapa, você congelará a base convolucional criada na etapa anterior e usará como extrator de recursos. Além disso, você adiciona um classificador em cima dele e treina o classificador de nível superior.

### Congele a base convolucional

É importante congelar a base convolucional antes de compilar e treinar o modelo. O congelamento (definindo layer.trainable = False) evita que os pesos em uma determinada camada sejam atualizados durante o treinamento. O MobileNet V2 tem muitas camadas, portanto, definir o sinalizador trainable de todo o modelo como False irá congelar todas elas.

### **Nota importante sobre camadas de `BatchNormalization`**
Muitos modelos contêm camadas `tf.keras.layers.BatchNormalization` . Essa camada é um caso especial e precauções devem ser tomadas no contexto do ajuste fino, conforme mostrado mais adiante neste tutorial.

Quando você define `layer.trainable = False` , a camada `BatchNormalization` será executada no modo de inferência e não atualizará suas estatísticas de média e variação.

Quando você descongela um modelo que contém camadas `BatchNormalization` para fazer o ajuste fino, você deve manter as camadas BatchNormalization no modo de inferência passando `training = False` ao chamar o modelo base. Caso contrário, as atualizações aplicadas aos pesos não treináveis ​​destruirão o que o modelo aprendeu.

Para obter mais detalhes, consulte o guia de aprendizado de transferência . [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning).
"""

base_model.trainable = False

# Let's take a look at the base model architecture
base_model.summary()

"""### Adicionar um cabeçalho de classificação

Para gerar previsões a partir do bloco de feições, calcule a média das localizações espaciais `5x5` , usando uma camada tf.keras.layers.`GlobalAveragePooling2D` para converter as feições em um único vetor de 1280 elementos por imagem.
"""

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
feature_batch_average = global_average_layer(feature_batch)
print(feature_batch_average.shape)

"""Aplique uma camada `tf.keras.layers.Dense` para converter esses recursos em uma única previsão por imagem. Você não precisa de uma função de ativação aqui porque essa previsão será tratada como um `logit` ou um valor bruto de previsão. Números positivos predizem a classe 1, números negativos predizem a classe 0."""

prediction_layer = tf.keras.layers.Dense(1, activation = "softmax")
prediction_batch = prediction_layer(feature_batch_average)
print(prediction_batch.shape)

"""Construa um modelo encadeando as camadas de aumento de dados, redimensionamento, `base_model` e extrator de recursos usando a [Keras Functional API](https://www.tensorflow.org/guide/keras/functional) . Como mencionado anteriormente, use `training=False` pois nosso modelo contém uma camada `BatchNormalization`.

"""

inputs = tf.keras.Input(shape=(160, 160, 3))
x = data_augmentation(inputs)
x = preprocess_input(x)
x = base_model(x, training=False)
x = global_average_layer(x)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense((1280))(x)
outputs = prediction_layer(x)
model = tf.keras.Model(inputs, outputs)

"""### Compilar o modelo
Compile o modelo antes de treiná-lo. Como existem duas classes, use a perda `tf.keras.losses.BinaryCrossentropy` com `from_logits=True` , pois o modelo fornece uma saída linear.



"""

base_learning_rate = 0.0001
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

"""Os 2,5 milhões de parâmetros no MobileNet estão congelados, mas existem 1,2 mil parâmetros treináveis na camada Dense. Estes são divididos entre dois objetos `tf.Variable` , os pesos e os bias."""

len(model.trainable_variables)

"""### Treine o modelo
Após treinar por 10 épocas, você deverá ver ~ 94% de precisão no conjunto de validação.

"""

initial_epochs = 20

loss0, accuracy0 = model.evaluate(validation_dataset)

print("initial loss: {:.2f}".format(loss0))
print("initial accuracy: {:.2f}".format(accuracy0))

history = model.fit(train_dataset,
                    epochs=initial_epochs,
                    validation_data=validation_dataset)

"""### Curvas de aprendizado
Vamos dar uma olhada nas curvas de aprendizado da precisão/perda de treinamento e validação ao usar o modelo base MobileNetV2 como um extrator de recursos fixo.
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""Nota: Se você está se perguntando por que as métricas de validação são claramente melhores do que as métricas de treinamento, o principal fator é porque camadas como `tf.keras.layers.BatchNormalization` e `tf.keras.layers.Dropout` afetam a precisão durante o treinamento. Eles são desativados ao calcular a perda de validação.

Em menor grau, também é porque as métricas de treinamento relatam a média de uma época, enquanto as métricas de validação são avaliadas após a época, portanto, as métricas de validação veem um modelo que foi treinado um pouco mais.

## Afinação
No experimento de extração de recursos, você estava treinando apenas algumas camadas em cima de um modelo base MobileNetV2. Os pesos da rede pré-treinada não foram atualizados durante o treinamento.

Uma maneira de aumentar ainda mais o desempenho é treinar (ou "ajustar") os pesos das camadas superiores do modelo pré-treinado juntamente com o treinamento do classificador que você adicionou. O processo de treinamento forçará os pesos a serem ajustados de mapas de recursos genéricos para recursos associados especificamente ao conjunto de dados.

  * Observação: isso só deve ser tentado depois de treinar o classificador de nível superior com o modelo pré-treinado definido como não treinável. Se você adicionar um classificador inicializado aleatoriamente em cima de um modelo pré-treinado e tentar treinar todas as camadas em conjunto, a magnitude das atualizações de gradiente será muito grande (devido aos pesos aleatórios do classificador) e seu modelo pré-treinado será esquecer o que aprendeu.

Além disso, você deve tentar ajustar um pequeno número de camadas superiores em vez de todo o modelo MobileNet. Na maioria das redes convolucionais, quanto mais alta uma camada, mais especializada ela é. As primeiras camadas aprendem recursos muito simples e genéricos que se generalizam para quase todos os tipos de imagens. À medida que você sobe, os recursos são cada vez mais específicos para o conjunto de dados no qual o modelo foi treinado. O objetivo do ajuste fino é adaptar esses recursos especializados para trabalhar com o novo conjunto de dados, em vez de substituir o aprendizado genérico.

### Descongele as camadas superiores do modelo

Tudo o que você precisa fazer é descongelar o `base_model` e definir as camadas inferiores como não treináveis. Em seguida, você deve recompilar o modelo (necessário para que essas alterações tenham efeito) e retomar o treinamento.
"""

base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))

# Fine-tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable = False

"""### Compilar o modelo
Como você está treinando um modelo muito maior e deseja readaptar os pesos pré-treinados, é importante usar uma taxa de aprendizado menor neste estágio. Caso contrário, seu modelo pode se ajustar muito rapidamente.
"""

model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),
              metrics=['accuracy'])

model.summary()

len(model.trainable_variables)

"""### Continue treinando o modelo

Se você treinou para convergência anteriormente, esta etapa melhorará sua precisão em alguns pontos percentuais.
"""

fine_tune_epochs = 10
total_epochs =  initial_epochs + fine_tune_epochs

history_fine = model.fit(train_dataset,
                         epochs=total_epochs,
                         initial_epoch=history.epoch[-1],
                         validation_data=validation_dataset)

"""Vamos dar uma olhada nas curvas de aprendizado da precisão/perda de treinamento e validação ao ajustar as últimas camadas do modelo base do MobileNetV2 e treinar o classificador em cima dele. A perda de validação é muito maior do que a perda de treinamento, então você pode ter algum overfitting.

Você também pode ter algum overfitting, pois o novo conjunto de treinamento é relativamente pequeno e semelhante aos conjuntos de dados originais do MobileNetV2.

Após o ajuste fino, o modelo atinge quase 98% de precisão no conjunto de validação.
"""

acc += history_fine.history['accuracy']
val_acc += history_fine.history['val_accuracy']

loss += history_fine.history['loss']
val_loss += history_fine.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.8, 1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""### Avaliação e previsão
Finalmente, você pode verificar o desempenho do modelo em novos dados usando o conjunto de teste.



"""

loss, accuracy = model.evaluate(test_dataset)
print('Test accuracy :', accuracy)

"""E agora você está pronto para usar esse modelo para prever se seu animal de estimação é um gato ou um cachorro.

"""

# Retrieve a batch of images from the test set
image_batch, label_batch = test_dataset.as_numpy_iterator().next()
predictions = model.predict_on_batch(image_batch).flatten()

# Apply a sigmoid since our model returns logits
predictions = tf.nn.sigmoid(predictions)
predictions = tf.where(predictions < 0.5, 0, 1)

print('Predictions:\n', predictions.numpy())
print('Labels:\n', label_batch)

plt.figure(figsize=(10, 10))
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image_batch[i].astype("uint8"))
  plt.title(class_names[predictions[i]])
  plt.axis("off")

"""## Resumo
* **Usando um modelo pré-treinado para extração de recursos** : ao trabalhar com um conjunto de dados pequeno, é uma prática comum aproveitar os recursos aprendidos por um modelo treinado em um conjunto de dados maior no mesmo domínio. Isso é feito instanciando o modelo pré-treinado e adicionando um classificador totalmente conectado no topo. O modelo pré-treinado é "congelado" e apenas os pesos do classificador são atualizados durante o treinamento. Nesse caso, a base convolucional extraiu todos os recursos associados a cada imagem e você acabou de treinar um classificador que determina a classe da imagem a partir desse conjunto de recursos extraídos.

* **Ajustando um modelo pré-treinado** : para melhorar ainda mais o desempenho, pode-se querer redirecionar as camadas de nível superior dos modelos pré-treinados para o novo conjunto de dados por meio de ajuste fino. Nesse caso, você ajustou seus pesos para que seu modelo aprendesse recursos de alto nível específicos para o conjunto de dados. Essa técnica geralmente é recomendada quando o conjunto de dados de treinamento é grande e muito semelhante ao conjunto de dados original no qual o modelo pré-treinado foi treinado.

"""